version: '3.8'

services:
  # PostgreSQL Database
  db:
    image: postgres:15-alpine
    container_name: scraper_db
    environment:
      POSTGRES_DB: scraper_db
      POSTGRES_USER: scraper_user
      POSTGRES_PASSWORD: scraper_pass
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U scraper_user -d scraper_db"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - scraper_network

  # Redis for Celery
  redis:
    image: redis:7-alpine
    container_name: scraper_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 5
    networks:
      - scraper_network

  # Django Backend
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: scraper_backend
    command: >
      sh -c "python manage.py migrate --noinput &&
             python manage.py collectstatic --noinput &&
             gunicorn --bind 0.0.0.0:8000 --workers 4 --timeout 120 config.wsgi:application"
    volumes:
      - ./backend:/app
      - static_volume:/app/staticfiles
      - media_volume:/app/media
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://scraper_user:scraper_pass@db:5432/scraper_db
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - DEBUG=True
      - ALLOWED_HOSTS=localhost,127.0.0.1,0.0.0.0,backend
      - CORS_ALLOWED_ORIGINS=http://localhost:3000,http://localhost:8080
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - scraper_network

  # Celery Worker
  celery_worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: scraper_celery_worker
    command: celery -A config worker -l info --concurrency=4
    volumes:
      - ./backend:/app
    environment:
      - DATABASE_URL=postgresql://scraper_user:scraper_pass@db:5432/scraper_db
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - scraper_network

  # Celery Beat (Scheduler)
  celery_beat:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: scraper_celery_beat
    command: celery -A config beat -l info --scheduler django_celery_beat.schedulers:DatabaseScheduler
    volumes:
      - ./backend:/app
    environment:
      - DATABASE_URL=postgresql://scraper_user:scraper_pass@db:5432/scraper_db
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    depends_on:
      db:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - scraper_network

  # Flower - Celery monitoring (optional)
  flower:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: scraper_flower
    command: celery -A config flower --port=5555
    ports:
      - "5555:5555"
    environment:
      - CELERY_BROKER_URL=redis://redis:6379/0
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
    depends_on:
      - redis
      - celery_worker
    networks:
      - scraper_network

networks:
  scraper_network:
    driver: bridge

volumes:
  postgres_data:
  redis_data:
  static_volume:
  media_volume:
